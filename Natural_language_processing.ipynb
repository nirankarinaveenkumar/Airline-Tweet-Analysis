{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural_language_processing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYftkrDLkoQv",
        "colab_type": "text"
      },
      "source": [
        "**Import all libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl8fhwsxLy1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "5d2a17b9-51c2-4488-cbbb-cd4cf309899d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import regex as re"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVQp3LvzL5hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/Harpreet/train.csv\",encoding = 'latin-1')\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Harpreet/test.csv\", encoding = 'latin-1')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFzhZ2IXF4st",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "6baa4f32-a9f9-41eb-82bc-b84f66ae7e11"
      },
      "source": [
        "data['Target'].value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1    4566\n",
              " 0    1536\n",
              " 1    1218\n",
              "Name: Target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQy8xBAl63AN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
        "                   \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
        "                   \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\", \n",
        "                   \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
        "                   \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
        "                   \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n",
        "                   \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
        "                   \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
        "                   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
        "                   \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
        "                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \n",
        "                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
        "                   \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
        "                   \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
        "                   \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
        "                   \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
        "                   \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
        "                   \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
        "                   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
        "                   \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
        "                   \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
        "                   \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
        "                   \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
        "                   \"this's\": \"this is\",\n",
        "                   \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n",
        "                   \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n",
        "                       \"here's\": \"here is\",\n",
        "                   \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
        "                   \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
        "                   \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
        "                   \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
        "                   \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
        "                   \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n",
        "                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
        "                   \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
        "                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
        "                   \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
        "                   \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
        "                   \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
        "                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
        "                   \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
        "                   \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"\n",
        "                   ,\"thnx\" : \"thanks\",\"flightr\":\"flight\" , \"turrible\":\"terrible\", \"flt\":\"flight\"}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6dybVJavxNd",
        "colab_type": "text"
      },
      "source": [
        "# **Custom Stop Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPBXzWPgttlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_stopwords = ['a','ain','abc','am','an','and','as','at','be','both','but','by','can','d','each','few','for',\n",
        "                    'from','further','had','hadn',\"hadn't\",'has','having','he','her','here','his','how','i',\n",
        "                    'if','in','into','it',\"it's\",'its','itself','ll','m','ma','me','o','or','ourselves','re',\n",
        "                    's','shan',\"shan't\",'she',\"she's\",'so','some','such','t','than','that','ve','we','y',\n",
        "                    'aa','aam','aa','ab','ac','ad','af','ah','al','am','an','ap','ar','as','at','au','aw','ay',\n",
        "                    'az','ba','bc','be','bf','bg','bk','bp','bs','bt','by','bz','ca','cb','cc','co','cp','cr',\n",
        "                    'cs','ct','cw','cx','dc','de','dl','dm','dr','eb','ed','eh','el','em','en','ep','er','eu',\n",
        "                    'ex','ey','fa','fb','fc','fe','ff','fi','fl','fm','fo','fr','ft','fu','gb','gf','gj','gt','ha',\n",
        "                    'he','hi','hm','hr','hv','id','ie','if','im','in','is','it','jb','jh','jj','jp','js','jt',\n",
        "                    'kc','kn','kp','ky','la','lb','ll','lt','lv','ma','mc','md','me','mi','mk','mn','mo','mp',\n",
        "                    'mr','ms','mt','mv','my','nc','nd','ne','ng','nh','nj','no','nt','nw','ny','oc','of','oh',\n",
        "                    'ok','on','or','os','ow','pa','pe','ph','pj','pm','pr','ps','pt','pu','qs','rd','re','rr',\n",
        "                    'rt','rx','sc','sf','sh','sm','so','sp','sr','st','sw','tb','tf','th','tn','to','tu','tv',\n",
        "                    'tx','ty','ua','uh','uk','um','un','up','ur','us','ut','uw','va','ve','vm','vp','vs','vt',\n",
        "                    'vx','wa','wc','wd','we','wi','wk','wn','wo','ws','wx','xm','xx','ya','yo','yr','zz']\n",
        "                    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmoJ5-7Lv9PB",
        "colab_type": "text"
      },
      "source": [
        "# **Custom Preprocessing /  Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNtUWNjXrjMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tweets(tweets):\n",
        "\n",
        "  # Remove \" ' \" \n",
        "  remove_contract = re.sub(\"â€™\",\"'\",tweets)\n",
        "\n",
        "  # Remove Flight Number\n",
        "  remove_flights = re.sub(\"\\w{1,4}\\d{1,6}\",\"\",remove_contract)\n",
        "\n",
        "\n",
        "  #Tokenization \n",
        "  tokens = remove_flights.lower().split()\n",
        "\n",
        "  # Contraction mapping and tokeinzation\n",
        "  split_contract = \" \".join([contraction_mapping[i] if i in contraction_mapping else i for i in tokens ])\n",
        "  \n",
        "  split_s = \" \".join([re.sub(\"'\\w\",\"\",split_contract)])\n",
        "  #Remove http website\n",
        "  remove_http = \" \".join([re.sub(\"http(.*)\",\"\",split_s)])\n",
        "\n",
        "  #Remove @ and preceding words\n",
        "  remove_atthe = \" \".join([re.sub(\"@[^\\s]+\",\"\",remove_http)])\n",
        "\n",
        "  #Remove # and preceding words\n",
        "  remove_hashtag = \" \".join([re.sub(r\"#([^\\s]+)\",\"\",remove_atthe)])\n",
        "\n",
        "  #Remove other unwanted things\n",
        "  only_letters = \" \".join([re.sub(\"[^a-zA-Z]\",\" \",remove_hashtag)])\n",
        "  only_letters = only_letters.split()\n",
        "\n",
        "  #stops = set(stopwords.words(\"english\"))\n",
        "  \n",
        "  final_words =[i for i in only_letters if i not in custom_stopwords]\n",
        "\n",
        "  return \" \".join(final_words)\n",
        " \n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYCq_8Twsl3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['new'] = data['text'].apply(lambda x: tweets(x))\n",
        "test_set = test['text'].apply(lambda x: tweets(x))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmrQK5a-Ew6x",
        "colab_type": "text"
      },
      "source": [
        "## **Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2MEOe-FIUmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCXl_utrJibn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = []\n",
        "for i in data['new'].str.split(\" \"):\n",
        "  for j in i:\n",
        "    tokens.append(word_tokenize(j))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Bk6zh8Fg2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "porter_token = []\n",
        "for i in tokens:\n",
        "  porter_token.append([stemmer.stem(token) for token in i])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG13liYXRnky",
        "colab_type": "text"
      },
      "source": [
        "Lemmitization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul3r9niLRtZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_output = []\n",
        "for i in tokens:\n",
        "  lemmatized_output.append([lemmatizer.lemmatize(token) for token in i])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWHPd7wUR_ZR",
        "colab_type": "text"
      },
      "source": [
        "Stemming and Lemmitization do not increase accuracy score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVVRsPh8vUa2",
        "colab_type": "text"
      },
      "source": [
        "**Vectorization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k3gGPjgyFaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "cvt = CountVectorizer()\n",
        "tfid = TfidfVectorizer()\n",
        "train = tfid.fit_transform(data['new'].values)\n",
        "test__ = tfid.transform(test_set.values)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od5CHBRSJKH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "5cec33e6-dd9c-4b8c-cac8-f3ab7a890ea0"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nhw5QPhJQBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "25ba425b-5a8e-42ea-f3c9-aa689cb30fb2"
      },
      "source": [
        "smt = SMOTE(random_state=1, k_neighbors=1)\n",
        "X_smote, y_smote =smt.fit_sample(train,data['Target'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVQSTy9NVZ8R",
        "colab_type": "text"
      },
      "source": [
        "# **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxMVWcstyjF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0xa2fa5yrXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = LogisticRegression()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7rPw9uByt-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = {'penalty':['l1','l2'],'solver':['lbfgs', 'saga'], 'C':[*range(7,9)]}\n",
        "grid_lr = GridSearchCV(lr,param_grid=param_grid,n_jobs=-1,scoring='f1_macro',cv=5)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8L2SutJaZkL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "cce9e45e-c873-4330-dbd6-059dd6509f07"
      },
      "source": [
        "grid_lr.fit(X_smote,y_smote)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'C': [7, 8], 'penalty': ['l1', 'l2'],\n",
              "                         'solver': ['lbfgs', 'saga']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1_macro', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2zXxtPQafBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3a531fd4-0297-4e17-b5da-47d4a5a745af"
      },
      "source": [
        "grid_lr.best_score_,grid_lr.best_params_"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8940161585249561, {'C': 8, 'penalty': 'l2', 'solver': 'saga'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngNphBkQy1D1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predicted = grid_lr.predict(X_smote)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGXpMGFHrTge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_smote,y_predicted)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dM4aijV5-Ci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "cce6b5e4-b010-419c-86b2-c86f105595ea"
      },
      "source": [
        "cm"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4464,   79,   23],\n",
              "       [  95, 4393,   78],\n",
              "       [  15,   28, 4523]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgEhBSGFrTi6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "512ca52d-0d68-422a-a152-a1e6afde63bb"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(y_smote, y_predicted, average = 'macro')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9767504740378037"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNSu8HNqoCvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kaggle_test = grid_lr.predict(test__)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezVl2mdYUlmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final = pd.DataFrame({'id':test.id,'Target':kaggle_test})\n",
        "final.to_csv(\"suppose.csv\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfaZ2FX0VT7f",
        "colab_type": "text"
      },
      "source": [
        "# **Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdcY7AGmUlt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLKhbBOQUlwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "naive = GaussianNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOXXEPHCUuzO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "5273f34d-e272-455a-9f3c-3767b8b8b682"
      },
      "source": [
        "param_grids_naive ={'var_smoothing':[ 1e-4,1e-2]}\n",
        "grid_naive = GridSearchCV(naive,param_grid=param_grids_naive,n_jobs=-1,scoring='f1_macro')\n",
        "grid_naive.fit(X_train.todense(),y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=GaussianNB(priors=None, var_smoothing=1e-09),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'var_smoothing': [0.0001]}, pre_dispatch='2*n_jobs',\n",
              "             refit=True, return_train_score=False, scoring='f1_macro',\n",
              "             verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 378
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v65ooGztUvCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_naive_pred = grid_naive.predict(X_test.todense())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P99F97HwUvFO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3323c690-136c-40e2-cc79-c210f44777c9"
      },
      "source": [
        "f1_score(y_test, y_naive_pred, average = 'macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7755690031479872"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 380
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiRKLLQoViVf",
        "colab_type": "text"
      },
      "source": [
        "# **XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laKc441IVlDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plPQIwXpW0vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb = XGBClassifier()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F050hHaGW6-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "36aad7a0-64c8-4607-d0e1-3d5f2e54af5c"
      },
      "source": [
        "params_grid_xgboost = {'gamma': [1],\n",
        "                       'max_depth': [11],\n",
        "                       'learning_rate':[0.1,0.2]}\n",
        "\n",
        "grid_xgboost = GridSearchCV(xgb,param_grid = params_grid_xgboost,n_jobs=-1,scoring='f1_macro')\n",
        "grid_xgboost.fit(X_smote,y_smote)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                     colsample_bylevel=1, colsample_bynode=1,\n",
              "                                     colsample_bytree=1, gamma=0,\n",
              "                                     learning_rate=0.1, max_delta_step=0,\n",
              "                                     max_depth=3, min_child_weight=1,\n",
              "                                     missing=None, n_estimators=100, n_jobs=1,\n",
              "                                     nthread=None, objective='binary:logistic',\n",
              "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
              "                                     scale_pos_weight=1, seed=None, silent=None,\n",
              "                                     subsample=1, verbosity=1),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'gamma': [1], 'learning_rate': [0.1, 0.2],\n",
              "                         'max_depth': [11]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1_macro', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUHQnD6PiKYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7cd26004-3054-4e63-8d9f-13d01396c343"
      },
      "source": [
        "grid_xgboost.best_score_,grid_xgboost.best_params_"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.867888128324491, {'gamma': 1, 'learning_rate': 0.2, 'max_depth': 11})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yk_fzufXA1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_xgb_predict = grid_xgboost.predict(X_smote)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L1YqArHXFk6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5dfac5dc-7503-4e3f-a8ab-68cd64e1fb69"
      },
      "source": [
        "f1_score(y_test, y_xgb_predict, average = 'macro')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9619186538002293"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1o63vkEDnKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "41c9c565-827f-4a27-e5b0-9aceef044182"
      },
      "source": [
        "confusion_matrix(y_smote,y_xgb_predict)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4331,  202,   33],\n",
              "       [  67, 4456,   43],\n",
              "       [ 108,  104, 4354]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYTR3V5Sr6Mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_prdddd = grid_xgboost.predict(test__)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I22Ehj5JsIcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final = pd.DataFrame({'id':test.id,'Target':y_prdddd})\n",
        "final.to_csv(\"xgboost_pred.csv\")"
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}